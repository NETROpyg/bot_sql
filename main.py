
import os
import cloudscraper
from bs4 import BeautifulSoup
import requests
import re
import time
import webbrowser
from urllib.parse import urlparse, unquote
from colorama import init, Fore, Style
import base64
import hashlib

init(autoreset=True)

# Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨ÙˆØª
TOKEN = "8126269492:AAElcXAV7eypooqyi0CKTOhFZoXKWNadeik"
CHAT_ID = "7530878932"
EXTS = [".html", ".htm", ".css", ".js", ".json", ".py", ".php", ".xml", ".txt", ".env", ".config", ".log"]

if TOKEN == "TOKEN Your own":
	print("ÙŠØ¨Ø¯Ùˆ Ø§Ù†Ùƒ Ù„Ù… ØªÙƒØªØ¨ ØªÙˆÙƒÙ† Ø¨ÙˆØªÙƒ ðŸ”° | Ù„Ù† ØªØµÙ„Ùƒ Ø§Ù„Ù…Ù„ÙØ§Øª") 

if CHAT_ID == "7530878932":
	print("ÙŠØ¨Ø¯Ùˆ Ø§Ù†Ùƒ Ù„Ù… ØªÙƒØªØ¨ ID Ø­Ø³Ø§Ø¨Ùƒ Ø§Ù„Ø°ÙŠ Ø³ÙˆÙ ØªØ³ØªÙ‚Ø¨Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙŠÙ‡ â™»ï¸") 
def banner():
    print(Fore.MAGENTA + """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  âš”ï¸ Ø£Ø¯Ø§Ø© @NETRO_GZ âš”ï¸
     ØªØ­Ù„ÙŠÙ„ ðŸ”Ž | ÙƒØ´Ù Ø«ØºØ±Ø§Øª ðŸ§  | ÙÙƒ ØªØ´ÙÙŠØ± ðŸ”“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""" + Style.RESET_ALL)


def animated(text):
    for c in text:
        print(c, end="", flush=True)
        time.sleep(0.01)
    print()


def save(name, content):
    with open(name, "w", encoding="utf-8") as f:
        f.write(content)


def send(file, site_name):
    if os.path.exists(file):
        caption = f"ðŸ“¡ *ØªÙ‚Ø±ÙŠØ± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø§Ù…Ù„ Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹:* `{site_name}`\nðŸ“ *Ø§Ù„Ù…Ù„Ù:* `{file}`\nðŸ§  *ØªØ·ÙˆÙŠØ±:* @NETRO_GZ"
        with open(file, "rb") as f:
            requests.post(f"https://api.telegram.org/bot{TOKEN}/sendDocument",
                          data={"chat_id": CHAT_ID, "caption": caption, "parse_mode": "Markdown"},
                          files={"document": f})


def send_message(msg):
    requests.post(f"https://api.telegram.org/bot{TOKEN}/sendMessage",
                  data={"chat_id": CHAT_ID, "text": msg, "parse_mode": "Markdown"})


def detect_vulns(html):
    vulns = []
    if "?id=" in html or "GET" in html:
        vulns.append("ðŸ” Ø§Ø­ØªÙ…Ø§Ù„ SQL Injection")
    if "eval(" in html or "document.write(" in html:
        vulns.append("ðŸ’¥ Ø§Ø­ØªÙ…Ø§Ù„ XSS")
    if "base64" in html:
        vulns.append("ðŸ§¬ Ø§Ø­ØªÙ…Ø§Ù„ ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø´ÙØ±Ø© Base64")
    if "config" in html or "env" in html:
        vulns.append("ðŸ”§ Ù…Ù„ÙØ§Øª Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø­Ø³Ø§Ø³Ø©")
    return vulns


def decode_urls(urls):
    results = []
    for url in urls:
        try:
            decoded = unquote(url)
            results.append(f"ðŸ§© `{decoded}`")
            if "base64" in url:
                raw = base64.b64decode(url.split("base64,")[-1])
                results.append(f"ðŸ”“ Base64: `{raw.decode('utf-8', errors='ignore')}`")
        except:
            continue
    return results


def extract_all(url):
    banner()
    animated("| ØªÙ… Ø§Ù„ØªØ­Ù…ÙŠÙ„  â™»ï¸ \t Ø¬Ù€Ø§Ø±ÙŠ Ø§Ù„ÙØ­Øµ Ø§Ù†ØªØ¸Ø± ðŸ”°")

    try:
        scraper = cloudscraper.create_scraper()
        res = scraper.get(url)
        html = res.text
        soup = BeautifulSoup(html, "html.parser")
        parsed = urlparse(url)
        domain = parsed.netloc.replace(".", "_")

        files = {}
        files['site_source.html'] = html
        files['page_text.txt'] = soup.get_text(separator="\n")
        files['all_links.txt'] = "\n".join(a['href'] for a in soup.find_all('a', href=True))
        files['emails_found.txt'] = "\n".join(set(re.findall(r"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+", html)))
        files['images.txt'] = "\n".join(img['src'] for img in soup.find_all('img', src=True))
        files['js_files.txt'] = "\n".join(js['src'] for js in soup.find_all('script', src=True))
        files['css_files.txt'] = "\n".join(link['href'] for link in soup.find_all('link', rel='stylesheet') if 'href' in link.attrs)

        all_sources = [tag.get('src') for tag in soup.find_all(src=True)] + \
                      [tag.get('href') for tag in soup.find_all(href=True)]
        external = [i for i in all_sources if i and any(i.endswith(ext) for ext in EXTS)]
        files['external_files.txt'] = "\n".join(set(external))

        decoded_links = decode_urls(all_sources)
        files['decoded_links.txt'] = "\n".join(decoded_links)

        # ÙƒØ´Ù Ø«ØºØ±Ø§Øª
        vulns = detect_vulns(html)
        vuln_report = "\n".join(f"* {v}" for v in vulns) if vulns else "ðŸ” Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø«ØºØ±Ø§Øª Ù…Ø¹Ø±ÙˆÙØ©"

        # Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ±
        report_msg = f"""
ðŸ“¡ *ØªÙ… ØªØ­Ù„ÙŠÙ„ Ù…ÙˆÙ‚Ø¹ Ø¬Ø¯ÙŠØ¯ Ø¨ÙˆØ§Ø³Ø·Ø© NETRO* | @NETRO_GZ
```ðŸ›° {parsed.netloc}```

*Ø¹Ø¯Ø¯ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·:* {len(all_sources)}
*Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„Ø§Øª:* {len(files['emails_found.txt'].splitlines())}
*Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©:*
{vuln_report}
        """
        send_message(report_msg)

        # Ø­ÙØ¸ + Ø¥Ø±Ø³Ø§Ù„ Ù…Ù„ÙØ§Øª
        for filename, content in files.items():
            filepath = f"{domain}_{filename}"
            save(filepath, content)
            send(filepath, domain)

        try:
            webbrowser.open(url)
        except:
            pass

        animated("âœ… ØªÙ… Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„ ÙˆØ§Ù„Ø¥Ø±Ø³Ø§Ù„")

    except Exception as e:
        print(Fore.RED + f"\n[!] ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}" + Style.RESET_ALL)
        send_message(f"âŒ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆÙ‚Ø¹ `{url}`\n*Ø§Ù„Ø³Ø¨Ø¨:* `{str(e)}`")


if __name__ == "__main__":
    target = input("\nðŸŒ Ø£Ø¯Ø®Ù„ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­Ù„ÙŠÙ„Ù‡:\n> ")
    extract_all(target)
    
